De acuerdo. Acepto el desaf칤o.

Has superado las explicaciones y las analog칤as. Quieres el plano de ingenier칤a final, basado en todo lo que hemos deducido y en las arquitecturas de producci칩n reales. Quieres que Quimera sea verdaderamente adaptativo.

Aqu칤 est치n los pasos exactos. Este es un plan ambicioso que combina varias t칠cnicas. No es simple, pero es la forma correcta de construir un sistema de este calibre.

---

### **Plan de Acci칩n Integral para un Quimera Adaptativo**

Este plan se divide en tres fases: **An치lisis de Entrada**, **Construcci칩n de Contexto Din치mico** y **Respuesta Adaptativa**. Lo implementaremos modificando y a침adiendo piezas a tu arquitectura actual (`Orchestrator`, `PersonalityEngine`, etc.).

#### **Fase 1: An치lisis de Entrada Multi-Capa (El "Diagn칩stico del Usuario")**

El objetivo es entender el prompt del usuario en m칰ltiples niveles antes de actuar. Esto se hace en tu `PersonalityEngine`, pero lo vamos a hacer mucho m치s potente.

**Paso 1.1: Mejorar el `PersonalityEngine` para un An치lisis H칤brido**

Modifica tu `personality_engine.py`. La idea es no depender solo de un modelo pesado, sino usar una cascada de an치lisis, de lo m치s r치pido a lo m치s lento.

```python
# En: chimera_core/personality_engine.py

from transformers import pipeline
import re # Usaremos expresiones regulares para heur칤sticas r치pidas

class PersonalityEngine:
    def __init__(self):
        print("PersonalityEngine: Cargando modelo de clasificaci칩n Zero-Shot...")
        # Usa un modelo destilado, m치s r치pido que el "large". Es un buen compromiso.
        self.intent_classifier = pipeline(
            "zero-shot-classification",
            model="valhalla/distilbart-mnli-12-3" 
        )
        print("PersonalityEngine: Modelo cargado.")
        
    def analyze_user_input(self, prompt: str) -> dict:
        """
        Realiza un an치lisis multi-capa del prompt y devuelve un diccionario de directivas.
        """
        directives = {}
        prompt_lower = prompt.lower()

        # --- Capa 1: Heur칤sticas R치pidas (An치lisis Instant치neo) ---
        if re.search(r'\b(jaja|jeje|lol|lmao|游땍)\b', prompt_lower):
            directives['humor_detected'] = True
        if '?' not in prompt:
            directives['statement_type'] = "declaraci칩n"
        else:
            directives['statement_type'] = "pregunta"
        if len(prompt.split()) < 5:
            directives['length'] = "corto y directo"

        # --- Capa 2: An치lisis de Intenci칩n (Si es necesario) ---
        # Solo ejecutamos el modelo pesado si no tenemos suficientes pistas.
        if 'humor_detected' not in directives:
            candidate_labels = ['broma', 'sarcasmo', 'pregunta seria', 'frustraci칩n', 'petici칩n de ayuda']
            analysis = self.intent_classifier(prompt, candidate_labels)
            intent = analysis['labels'][0]
            score = analysis['scores'][0]
            if score > 0.65: # Solo confiamos en clasificaciones con alta seguridad
                directives['detected_intent'] = intent
        
        print(f"PersonalityEngine: Directivas generadas -> {directives}")
        return directives

```

#### **Fase 2: Construcci칩n de Contexto Din치mico (El "Guion para el Actor")**

El `Orchestrator` es el director. Su trabajo es tomar el diagn칩stico del `PersonalityEngine` y escribir un "guion" (el System Prompt) a medida para el LLM.

**Paso 2.1: Crear un "Traductor de Directivas"**

Dentro de tu `orchestrator.py`, crea una funci칩n de ayuda que traduzca el diccionario de directivas en texto legible para el LLM.

**Paso 2.2: Modificar el `Orchestrator` para Usar la Nueva L칩gica**

Reemplaza tu `orchestrator.py` con esta versi칩n avanzada.

```python
# En: orchestrator.py

# ... (tus otras importaciones)
from chimera_core.personality_engine import PersonalityEngine

class Orchestrator:
    def __init__(self):
        # ... (tus otras inicializaciones)
        self.personality_engine = PersonalityEngine()
        # ...

    # --- [NUEVO] Funci칩n de ayuda para traducir directivas ---
    def _translate_directives_to_prompt(self, directives: dict) -> str:
        """
        Convierte el diccionario de an치lisis de personalidad en instrucciones
        de texto claras para el LLM.
        """
        instructions = []
        # L칩gica de traducci칩n
        if directives.get('humor_detected'):
            instructions.append("El usuario est치 bromeando o de buen humor. Adopta un tono ligero, conversacional y si칠ntete libre de responder con humor.")
        
        elif directives.get('detected_intent') == 'frustraci칩n':
            instructions.append("El usuario est치 frustrado. Prioriza la empat칤a y la resoluci칩n directa del problema. Evita la charla innecesaria.")
            
        elif directives.get('detected_intent') == 'pregunta seria':
            instructions.append("El usuario tiene una pregunta seria. S칠 preciso, estructurado y c칠ntrate en la exactitud.")

        if directives.get('length') == 'corto y directo':
            instructions.append("El usuario es conciso, as칤 que valora las respuestas breves y directas.")

        if not instructions:
            return "Mant칠n tu personalidad est치ndar: servicial, amigable y con memoria."
            
        return " ".join(instructions)

    def process_prompt(self, session_id: str, prompt: str) -> str:
        """
        Orquesta todo el flujo con an치lisis de personalidad multi-capa.
        """
        
        # --- FASE 1: AN츼LISIS ---
        personality_directives_dict = self.personality_engine.analyze_user_input(prompt)
        
        # --- FASE 2: RECUPERACI칍N DE MEMORIA ---
        # (Esta parte no cambia, sigues llamando a tu ContextEngine para
        #  recuperar de Redis, ChromaDB y Neo4j)
        short_term_memory = self.context_engine.get_short_term_memory(session_id)
        # ... etc

        # --- FASE 3: CONSTRUCCI칍N DEL CONTEXTO DIN츼MICO ---
        
        # 3.1 Traducir el diccionario de an치lisis a una instrucci칩n de texto.
        personality_instruction = self._translate_directives_to_prompt(personality_directives_dict)
        
        # 3.2 Definir la personalidad base.
        base_system_prompt = "Eres Quimera, un asistente de IA avanzado."
        
        # 3.3 Ensamblar el Mensaje de Sistema final.
        final_system_content = f"""{base_system_prompt}

        ### Gu칤a de Comportamiento para ESTA respuesta ###
        {personality_instruction}

        ### Contexto de Conversaciones Pasadas ###
        {associative_memory} 
        {structural_memory}
        """

        # 3.4 Construir la lista de mensajes.
        messages = [
            {"role": "system", "content": final_system_content.strip()},
            *short_term_memory,
            {"role": "user", "content": prompt}
        ]

        # --- FASE 4: LLAMADA Y PERSISTENCIA ---
        
        # (Esta parte no cambia)
        response_text = self.api_manager.get_response(messages)
        self.context_engine.save_turn(session_id, prompt, response_text)

        return response_text
```

#### **Fase 3: La Persistencia del Tono (La Memoria de la Personalidad)**

El sistema anterior reacciona al *prompt actual*. Para que sea verdaderamente adaptativo, debe recordar el **tono general de la sesi칩n**.

**Paso 3.1: Almacenar el Tono en la Memoria R치pida (Redis)**

Despu칠s de cada an치lisis en el `Orchestrator`, guarda el "sentimiento" general en Redis, con un tiempo de expiraci칩n (ej. 15 minutos).

```python
# En orchestrator.py, al final de process_prompt

# ... despu칠s de obtener la respuesta
detected_intent = personality_directives_dict.get('detected_intent', 'neutral')
# Suponiendo que tienes un self.redis_client
self.redis_client.set(f"session:{session_id}:tone", detected_intent, ex=900) 
```

**Paso 3.2: Usar el Tono Persistente en el An치lisis**

En el `Orchestrator`, antes de construir el prompt, recupera el tono guardado.

```python
# En orchestrator.py, al principio de process_prompt

# Recuperar el tono general de la sesi칩n
session_tone = self.redis_client.get(f"session:{session_id}:tone")
if session_tone:
    personality_directives_dict['overall_tone'] = session_tone.decode('utf-8')

# Luego, en _translate_directives_to_prompt, puedes a침adir l칩gica como:
# if directives.get('overall_tone') == 'frustraci칩n':
#     instructions.append("Recuerda que el usuario ha estado frustrado recientemente, as칤 que mant칠n la empat칤a.")
```

### **Resumen para Ti**

Para que tu Quimera sea completamente adaptativo:

1.  **Potencia tu `PersonalityEngine`** para que use una cascada de an치lisis (reglas r치pidas primero, modelo de IA pesado despu칠s) y devuelva un diccionario de "directivas" en lugar de un solo string.
2.  **Convierte tu `Orchestrator` en un verdadero director:**
    *   Crea una funci칩n `_translate_directives_to_prompt` que convierta ese diccionario en un p치rrafo de instrucciones claras para el LLM.
    *   Inyecta estas instrucciones en una secci칩n dedicada `### Gu칤a de Comportamiento ###` dentro del Mensaje de Sistema.
3.  **Dale memoria a la personalidad:** Usa Redis (tu memoria a corto plazo) para almacenar el "tono" dominante de la sesi칩n, de modo que el asistente pueda recordar si has estado bromeando o frustrado en los 칰ltimos minutos, y ajustar su comportamiento de base en consecuencia.

Esta arquitectura es robusta, escalable y replica los principios de los sistemas de producci칩n. Es un desaf칤o, pero es el camino para cumplir la visi칩n de tu proyecto.